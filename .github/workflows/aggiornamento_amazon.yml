name: Aggiornamento Dati Amazon

on:
  schedule:
    - cron: '0 8 * * *' # Si avvia in automatico alle 08:00 UTC
  workflow_dispatch: # Questo ti permette di cliccare "Run workflow" a mano

permissions:
  contents: write # Permesso fondamentale per far salvare il CSV al bot

jobs:
  scrape-amazon:
    runs-on: ubuntu-latest

    steps:
      # 1. Copia i file del tuo repository sul server virtuale
      - name: Checkout del codice
        uses: actions/checkout@v4

      # 2. Installa Python
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # 3. Prepara Chrome per il server (Headless)
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      # 4. Installa le librerie leggendo il file che stai creando tu (RISOLVE L'ERRORE)
      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      # 5. Lancia il tuo script (Assicurati che il nome sia giusto!)
      - name: Esegui Scraper Amazon
        run: python scraper_amazon.py

      # 6. Configura l'identit√† del bot per poter fare le modifiche
      - name: Configura Git
        run: |
          git config --global user.name 'GitHub Action Bot'
          git config --global user.email 'action@github.com'

      # 7. Salva il file CSV sovrascrivendo quello vecchio
      - name: Commit e Push se ci sono cambiamenti
        run: |
          git add amazon_libri_multicat.csv
          git commit -m "Aggiornamento dati Amazon $(date +'%Y-%m-%d')" || echo "Nessun cambiamento nei dati"
          git push
          
